{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Natural Language Processing (NLP) Review Lab\n",
    "\n",
    "_Authors: Joseph Nelson (DC)_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note: This lab is intended to be done as a walkthrough with the instructor.**\n",
    "\n",
    "## Introduction\n",
    "\n",
    "\n",
    "*Adapted from [NLP Crash Course](http://files.meetup.com/7616132/DC-NLP-2013-09%20Charlie%20Greenbacker.pdf) by Charlie Greenbacker, [Introduction to NLP](http://spark-public.s3.amazonaws.com/nlp/slides/intro.pdf) by Dan Jurafsky, Kevin Markham's Data School Curriculum*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is NLP?\n",
    "\n",
    "- Using computers to process (analyze, understand, generate) natural human languages\n",
    "- Most knowledge created by humans is unstructured text, and we need a way to make sense of it\n",
    "- Build probabilistic model using data about a language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are some of the higher level task areas?\n",
    "\n",
    "- **Information retrieval**: Find relevant results and similar results\n",
    "    - [Google](https://www.google.com/)\n",
    "- **Information extraction**: Structured information from unstructured documents\n",
    "    - [Events from Gmail](https://support.google.com/calendar/answer/6084018?hl=en)\n",
    "- **Machine translation**: One language to another\n",
    "    - [Google Translate](https://translate.google.com/)\n",
    "- **Text simplification**: Preserve the meaning of text, but simplify the grammar and vocabulary\n",
    "    - [Rewordify](https://rewordify.com/)\n",
    "    - [Simple English Wikipedia](https://simple.wikipedia.org/wiki/Main_Page)\n",
    "- **Predictive text input**: Faster or easier typing\n",
    "    - [My application](https://justmarkham.shinyapps.io/textprediction/)\n",
    "    - [A much better application](https://farsite.shinyapps.io/swiftkey-cap/)\n",
    "- **Sentiment analysis**: Attitude of speaker\n",
    "    - [Hater News](http://haternews.herokuapp.com/)\n",
    "- **Automatic summarization**: Extractive or abstractive summarization\n",
    "    - [autotldr](https://www.reddit.com/r/technology/comments/35brc8/21_million_people_still_use_aol_dialup/cr2zzj0)\n",
    "- **Natural Language Generation**: Generate text from data\n",
    "    - [How a computer describes a sports match](http://www.bbc.com/news/technology-34204052)\n",
    "    - [Publishers withdraw more than 120 gibberish papers](http://www.nature.com/news/publishers-withdraw-more-than-120-gibberish-papers-1.14763)\n",
    "- **Speech recognition and generation**: Speech-to-text, text-to-speech\n",
    "    - [Google's Web Speech API demo](https://www.google.com/intl/en/chrome/demos/speech.html)\n",
    "    - [Vocalware Text-to-Speech demo](https://www.vocalware.com/index/demo)\n",
    "- **Question answering**: Determine the intent of the question, match query with knowledge base, evaluate hypotheses\n",
    "    - [How did supercomputer Watson beat Jeopardy champion Ken Jennings?](http://blog.ted.com/how-did-supercomputer-watson-beat-jeopardy-champion-ken-jennings-experts-discuss/)\n",
    "    - [IBM's Watson Trivia Challenge](http://www.nytimes.com/interactive/2010/06/16/magazine/watson-trivia-game.html)\n",
    "    - [The AI Behind Watson](http://www.aaai.org/Magazine/Watson/watson.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are some of the lower level components?\n",
    "\n",
    "- **Tokenization**: breaking text into tokens (words, sentences, n-grams)\n",
    "- **Stopword removal**: a/an/the\n",
    "- **Stemming and lemmatization**: root word\n",
    "- **TF-IDF**: word importance\n",
    "- **Part-of-speech tagging**: noun/verb/adjective\n",
    "- **Named entity recognition**: person/organization/location\n",
    "- **Spelling correction**: \"New Yrok City\"\n",
    "- **Word sense disambiguation**: \"buy a mouse\"\n",
    "- **Segmentation**: \"New York City subway\"\n",
    "- **Language detection**: \"translate this page\"\n",
    "- **Machine learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is NLP hard?\n",
    "\n",
    "- **Ambiguity**:\n",
    "    - Hospitals are Sued by 7 Foot Doctors\n",
    "    - Juvenile Court to Try Shooting Defendant\n",
    "    - Local High School Dropouts Cut in Half\n",
    "- **Non-standard English**: text messages\n",
    "- **Idioms**: \"throw in the towel\"\n",
    "- **Newly coined words**: \"retweet\"\n",
    "- **Tricky entity names**: \"Where is A Bug's Life playing?\"\n",
    "- **World knowledge**: \"Mary and Sue are sisters\", \"Mary and Sue are mothers\"\n",
    "\n",
    "NLP requires an understanding of the **language** and the **world**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Reading in the Yelp Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"corpus\" = collection of documents\n",
    "- \"corpora\" = plural form of corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = '../../data/yelp.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Subset the reviews to best and worst.\n",
    "\n",
    "- Select only 5-star and 1-star reviews.\n",
    "- The text will be the features, the stars will be the target.\n",
    "- Create a train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read yelp.csv into a DataFrame\n",
    "yelp = pd.read_csv(csv_file)\n",
    "\n",
    "# create a new DataFrame that only contains the 5-star and 1-star reviews\n",
    "yelp_best_worst = yelp[(yelp.stars==5) | (yelp.stars==1)]\n",
    "\n",
    "# define X and y\n",
    "X = yelp_best_worst.text\n",
    "y = yelp_best_worst.stars\n",
    "\n",
    "# split the new DataFrame into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3064,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3064,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have no idea why some people give bad reviews about this place. It goes to show you, you can please everyone. They are probably griping about something that their own fault...there are many people like that.\\n\\nIn any case, my friend and I arrived at about 5:50 PM this past Sunday. It was pretty crowded, more than I thought for a Sunday evening and thought we would have to wait forever to get a seat but they said we\\'ll be seated when the girl comes back from seating someone else. We were seated at 5:52 and the waiter came and got our drink orders. Everyone was very pleasant from the host that seated us to the waiter to the server. The prices were very good as well. We placed our orders once we decided what we wanted at 6:02. We shared the baked spaghetti calzone and the small \"Here\\'s The Beef\" pizza so we can both try them. The calzone was huge and we got the smallest one (personal) and got the small 11\" pizza. Both were awesome! My friend liked the pizza better and I liked the calzone better. The calzone does have a sweetish sauce but that\\'s how I like my sauce!\\n\\nWe had to box part of the pizza to take it home and we were out the door by 6:42. So, everything was great and not like these bad reviewers. That goes to show you that  you have to try these things yourself because all these bad reviewers have some serious issues.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_best_worst.ix[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3064\n",
      "1022\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **What:** Separate text into units such as sentences or words\n",
    "- **Why:** Gives structure to previously unstructured text\n",
    "- **Notes:** Relatively easy with English language text, not easy with some languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Use CountVectorizer to convert the training and testing text data.\n",
    "\n",
    "[CountVectorizer documentation](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n",
    "\n",
    "- **lowercase:** boolean, True by default\n",
    "    - Convert all characters to lowercase before tokenizing.\n",
    "- **ngram_range:** tuple (min_n, max_n)\n",
    "    - The lower and upper boundary of the range of n-values for different n-grams to be extracted. All values of n such that min_n <= n <= max_n will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use CountVectorizer to create document-term matrices from X_train and X_test\n",
    "vect = CountVectorizer()\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3064, 16825)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows are documents, columns are terms (aka \"tokens\" or \"features\")\n",
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'yyyyy', u'z11', u'za', u'zabba', u'zach', u'zam', u'zanella', u'zankou', u'zappos', u'zatsiki', u'zen', u'zero', u'zest', u'zexperience', u'zha', u'zhou', u'zia', u'zihuatenejo', u'zilch', u'zin', u'zinburger', u'zinburgergeist', u'zinc', u'zinfandel', u'zing', u'zip', u'zipcar', u'zipper', u'zippers', u'zipps', u'ziti', u'zoe', u'zombi', u'zombies', u'zone', u'zones', u'zoning', u'zoo', u'zoyo', u'zucca', u'zucchini', u'zuchinni', u'zumba', u'zupa', u'zuzu', u'zwiebel', u'zzed', u'\\xe9clairs', u'\\xe9cole', u'\\xe9m']\n"
     ]
    }
   ],
   "source": [
    "# last 50 features\n",
    "print(vect.get_feature_names()[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show vectorizer options\n",
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3064, 20838)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't convert to lowercase\n",
    "vect = CountVectorizer(lowercase=False)\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3064, 169847)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# include 1-grams and 2-grams\n",
    "vect = CountVectorizer(ngram_range=(1, 2))\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'zone out', u'zone when', u'zones', u'zones dolls', u'zoning', u'zoning issues', u'zoo', u'zoo and', u'zoo is', u'zoo not', u'zoo the', u'zoo ve', u'zoyo', u'zoyo for', u'zucca', u'zucca appetizer', u'zucchini', u'zucchini and', u'zucchini bread', u'zucchini broccoli', u'zucchini carrots', u'zucchini fries', u'zucchini pieces', u'zucchini strips', u'zucchini veal', u'zucchini very', u'zucchini with', u'zuchinni', u'zuchinni again', u'zuchinni the', u'zumba', u'zumba class', u'zumba or', u'zumba yogalates', u'zupa', u'zupa flavors', u'zuzu', u'zuzu in', u'zuzu is', u'zuzu the', u'zwiebel', u'zwiebel kr\\xe4uter', u'zzed', u'zzed in', u'\\xe9clairs', u'\\xe9clairs napoleons', u'\\xe9cole', u'\\xe9cole len\\xf4tre', u'\\xe9m', u'\\xe9m all']\n"
     ]
    }
   ],
   "source": [
    "# last 50 features\n",
    "print(vect.get_feature_names()[-50:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Predict the star rating with the new features from CountVectorizer.\n",
    "\n",
    "Validate on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.918786692759\n"
     ]
    }
   ],
   "source": [
    "# use default options for CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "\n",
    "# create document-term matrices\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "# use Naive Bayes  to predict the star rating\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "\n",
    "# calculate accuracy\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81996086105675148"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate null accuracy\n",
    "y_test_binary = np.where(y_test==5, 1, 0)\n",
    "max(y_test_binary.mean(), 1 - y_test_binary.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filly': 51749,\n",
       " 'only': 101633,\n",
       " 'reviews': 119034,\n",
       " 'nine': 95452,\n",
       " 'now': 97181,\n",
       " 'wow': 167344,\n",
       " 'do': 41612,\n",
       " 'miss': 89971,\n",
       " 'this': 146924,\n",
       " 'place': 109900,\n",
       " '24hrs': 938,\n",
       " 'drive': 43612,\n",
       " 'thru': 148108,\n",
       " 'or': 102359,\n",
       " 'walk': 158386,\n",
       " 'up': 154936,\n",
       " 'ridiculously': 119420,\n",
       " 'cheap': 28586,\n",
       " 'tasty': 138152,\n",
       " 'of': 97815,\n",
       " 'course': 34958,\n",
       " 'the': 140452,\n",
       " 'arizona': 12397,\n",
       " 'burritos': 24225,\n",
       " 'are': 11529,\n",
       " 'good': 60362,\n",
       " 'everything': 47889,\n",
       " 'is': 74210,\n",
       " 'used': 155788,\n",
       " 'to': 148972,\n",
       " 'love': 84314,\n",
       " 'one': 101149,\n",
       " 'combos': 32102,\n",
       " 'you': 168436,\n",
       " 'get': 58690,\n",
       " 'beef': 18342,\n",
       " 'burrito': 24175,\n",
       " 'taco': 137134,\n",
       " 'rice': 119204,\n",
       " 'and': 6933,\n",
       " 'beans': 17857,\n",
       " 'for': 54092,\n",
       " 'under': 154273,\n",
       " 'color': 31922,\n",
       " 'me': 87320,\n",
       " 'silly': 127345,\n",
       " 'call': 25868,\n",
       " 'sally': 121414,\n",
       " 'they': 146093,\n",
       " 'have': 65231,\n",
       " 'bomb': 21660,\n",
       " 'horchata': 69276,\n",
       " 'too': 151022,\n",
       " 'really': 116163,\n",
       " 'fresh': 56004,\n",
       " 'flautas': 52835,\n",
       " 'rolled': 120084,\n",
       " 'tacos': 137182,\n",
       " 'breakfast': 22815,\n",
       " 'damn': 37130,\n",
       " 'here': 67442,\n",
       " 'whether': 163354,\n",
       " 'drunk': 43811,\n",
       " 'sober': 129625,\n",
       " 'filly only': 51750,\n",
       " 'only reviews': 101888,\n",
       " 'reviews nine': 119068,\n",
       " 'nine now': 95454,\n",
       " 'now wow': 97359,\n",
       " 'wow do': 167355,\n",
       " 'do miss': 41705,\n",
       " 'miss this': 89991,\n",
       " 'this place': 147302,\n",
       " 'place 24hrs': 109901,\n",
       " '24hrs drive': 939,\n",
       " 'drive thru': 43652,\n",
       " 'thru or': 148117,\n",
       " 'or walk': 102934,\n",
       " 'walk up': 158416,\n",
       " 'up only': 155110,\n",
       " 'only ridiculously': 101889,\n",
       " 'ridiculously cheap': 119421,\n",
       " 'cheap ridiculously': 28629,\n",
       " 'ridiculously tasty': 119429,\n",
       " 'tasty of': 138210,\n",
       " 'of course': 98180,\n",
       " 'course the': 35019,\n",
       " 'the arizona': 140622,\n",
       " 'arizona burritos': 12406,\n",
       " 'burritos are': 24227,\n",
       " 'are good': 11755,\n",
       " 'good everything': 60506,\n",
       " 'everything is': 47938,\n",
       " 'is good': 74611,\n",
       " 'good used': 60806,\n",
       " 'used to': 155827,\n",
       " 'to love': 149810,\n",
       " 'love one': 84456,\n",
       " 'one of': 101359,\n",
       " 'of the': 99288,\n",
       " 'the combos': 141226,\n",
       " 'combos you': 32104,\n",
       " 'you get': 168605,\n",
       " 'get beef': 58723,\n",
       " 'beef burrito': 18351,\n",
       " 'burrito taco': 24211,\n",
       " 'taco rice': 137161,\n",
       " 'rice and': 119210,\n",
       " 'and beans': 7177,\n",
       " 'beans for': 17875,\n",
       " 'for under': 55032,\n",
       " 'under wow': 154320,\n",
       " 'wow color': 167352,\n",
       " 'color me': 31932,\n",
       " 'me silly': 87642,\n",
       " 'silly and': 127346,\n",
       " 'and call': 7329,\n",
       " 'call me': 25902,\n",
       " 'me sally': 87621,\n",
       " 'sally they': 121416,\n",
       " 'they have': 146257,\n",
       " 'have bomb': 65304,\n",
       " 'bomb horchata': 21669,\n",
       " 'horchata too': 69284,\n",
       " 'too really': 151182,\n",
       " 'really good': 116291,\n",
       " 'good and': 60385,\n",
       " 'and fresh': 7997,\n",
       " 'fresh flautas': 56057,\n",
       " 'flautas rolled': 52838,\n",
       " 'rolled tacos': 120092,\n",
       " 'tacos and': 137185,\n",
       " 'and breakfast': 7277,\n",
       " 'breakfast burritos': 22826,\n",
       " 'burritos damn': 24230,\n",
       " 'damn everything': 37139,\n",
       " 'everything here': 47934,\n",
       " 'here is': 67570,\n",
       " 'good whether': 60828,\n",
       " 'whether drunk': 163356,\n",
       " 'drunk or': 43820,\n",
       " 'or sober': 102835,\n",
       " 'my': 92393,\n",
       " 'husband': 70695,\n",
       " 'absolutely': 2246,\n",
       " 'restaurant': 118409,\n",
       " 'anytime': 10839,\n",
       " 'find': 51890,\n",
       " 'myself': 93403,\n",
       " 'craving': 35483,\n",
       " 'mexican': 89039,\n",
       " 'food': 53554,\n",
       " 'first': 52283,\n",
       " 'that': 139562,\n",
       " 'pops': 111453,\n",
       " 'in': 71596,\n",
       " 'head': 66321,\n",
       " 'salsa': 121498,\n",
       " 'blanca': 21112,\n",
       " 'we': 160833,\n",
       " 'always': 5528,\n",
       " 'encountered': 45884,\n",
       " 'friendly': 56425,\n",
       " 'welcoming': 161695,\n",
       " 'staff': 132541,\n",
       " 'amazing': 6059,\n",
       " 'fulfilling': 57531,\n",
       " 'what': 162642,\n",
       " 'more': 90817,\n",
       " 'could': 34535,\n",
       " 'ask': 13492,\n",
       " 'my husband': 92887,\n",
       " 'husband and': 70699,\n",
       " 'and absolutely': 6961,\n",
       " 'absolutely love': 2282,\n",
       " 'love this': 84517,\n",
       " 'this restaurant': 147347,\n",
       " 'restaurant anytime': 118421,\n",
       " 'anytime find': 10843,\n",
       " 'find myself': 51949,\n",
       " 'myself craving': 93417,\n",
       " 'craving mexican': 35493,\n",
       " 'mexican food': 89057,\n",
       " 'food the': 53902,\n",
       " 'the first': 141792,\n",
       " 'first place': 52419,\n",
       " 'place that': 110161,\n",
       " 'that pops': 140159,\n",
       " 'pops in': 111454,\n",
       " 'in my': 72125,\n",
       " 'my head': 92861,\n",
       " 'head is': 66336,\n",
       " 'is salsa': 75024,\n",
       " 'salsa blanca': 121511,\n",
       " 'blanca we': 21113,\n",
       " 'we have': 160974,\n",
       " 'have always': 65255,\n",
       " 'always encountered': 5592,\n",
       " 'encountered friendly': 45889,\n",
       " 'friendly welcoming': 56553,\n",
       " 'welcoming staff': 161712,\n",
       " 'staff and': 132550,\n",
       " 'and amazing': 7024,\n",
       " 'amazing fulfilling': 6142,\n",
       " 'fulfilling food': 57532,\n",
       " 'food what': 53951,\n",
       " 'what more': 162784,\n",
       " 'more could': 90879,\n",
       " 'could you': 34683,\n",
       " 'you ask': 168470,\n",
       " 'ask for': 13500,\n",
       " 'went': 161945,\n",
       " 'today': 150625,\n",
       " 'after': 3419,\n",
       " 'lunch': 84856,\n",
       " 'got': 61005,\n",
       " 'usual': 155894,\n",
       " 'lime': 82185,\n",
       " 'basil': 16972,\n",
       " 'real': 116014,\n",
       " 'mint': 89725,\n",
       " 'chip': 29788,\n",
       " 'which': 163372,\n",
       " 'leaves': 80697,\n",
       " 'hubby': 70313,\n",
       " 'chocolate': 29920,\n",
       " 'guiness': 62991,\n",
       " 'four': 55497,\n",
       " 'peaks': 107495,\n",
       " 'hop': 69176,\n",
       " 'knot': 79102,\n",
       " 'best': 19631,\n",
       " 'ice': 70841,\n",
       " 'cream': 35563,\n",
       " 'phoenix': 108842,\n",
       " 'super': 135860,\n",
       " 'nice': 94975,\n",
       " 'give': 59502,\n",
       " 'us': 155469,\n",
       " 'bags': 16091,\n",
       " 'take': 137335,\n",
       " 'our': 104072,\n",
       " 'home': 68766,\n",
       " 'we went': 161185,\n",
       " 'went today': 162003,\n",
       " 'today after': 150626,\n",
       " 'after lunch': 3547,\n",
       " 'lunch got': 84899,\n",
       " 'got my': 61114,\n",
       " 'my usual': 93335,\n",
       " 'usual of': 155912,\n",
       " 'of lime': 98650,\n",
       " 'lime basil': 82188,\n",
       " 'basil and': 16974,\n",
       " 'and real': 9065,\n",
       " 'real mint': 116074,\n",
       " 'mint chip': 89727,\n",
       " 'chip which': 29812,\n",
       " 'which love': 163471,\n",
       " 'love for': 84387,\n",
       " 'for the': 54988,\n",
       " 'the real': 143277,\n",
       " 'mint leaves': 89734,\n",
       " 'leaves and': 80698,\n",
       " 'and my': 8667,\n",
       " 'my hubby': 92882,\n",
       " 'hubby got': 70320,\n",
       " 'got chocolate': 61041,\n",
       " 'chocolate guiness': 29962,\n",
       " 'guiness and': 62992,\n",
       " 'and four': 7987,\n",
       " 'four peaks': 55531,\n",
       " 'peaks hop': 107503,\n",
       " 'hop knot': 69182,\n",
       " 'knot best': 79104,\n",
       " 'best ice': 19792,\n",
       " 'ice cream': 70851,\n",
       " 'cream in': 35607,\n",
       " 'in phoenix': 72203,\n",
       " 'phoenix the': 108968,\n",
       " 'the staff': 143758,\n",
       " 'staff is': 132611,\n",
       " 'is always': 74259,\n",
       " 'always super': 5768,\n",
       " 'super nice': 135928,\n",
       " 'nice they': 95156,\n",
       " 'they give': 146238,\n",
       " 'give us': 59560,\n",
       " 'us ice': 155566,\n",
       " 'ice bags': 70845,\n",
       " 'bags to': 16109,\n",
       " 'to take': 150371,\n",
       " 'take our': 137410,\n",
       " 'our ice': 104270,\n",
       " 'cream home': 35606,\n",
       " 'home love': 68836,\n",
       " 'totally': 151674,\n",
       " 'dissapointed': 41422,\n",
       " 'had': 63331,\n",
       " 'purchased': 114235,\n",
       " 'coupon': 34924,\n",
       " 'from': 56806,\n",
       " 'travelzoo': 152388,\n",
       " 'try': 153115,\n",
       " 'out': 104507,\n",
       " 'given': 59570,\n",
       " 'its': 76534,\n",
       " 'location': 83467,\n",
       " 'would': 167121,\n",
       " 'thought': 147747,\n",
       " 'it': 75467,\n",
       " 'was': 158994,\n",
       " 'going': 60183,\n",
       " 'be': 17223,\n",
       " 'very': 156938,\n",
       " 'upscale': 155380,\n",
       " 'were': 162022,\n",
       " 'expecting': 48612,\n",
       " 'whole': 164065,\n",
       " 'lot': 84138,\n",
       " 'service': 124997,\n",
       " 'great': 61667,\n",
       " 'but': 24480,\n",
       " 'not': 96289,\n",
       " 'worth': 167056,\n",
       " 'itself': 76701,\n",
       " 'outdated': 104825,\n",
       " '80': 1634,\n",
       " 'crab': 35275,\n",
       " 'cakes': 25785,\n",
       " 'appertizer': 11142,\n",
       " 'cold': 31795,\n",
       " 'when': 162976,\n",
       " 'served': 124781,\n",
       " 'told': 150786,\n",
       " 'waiter': 158182,\n",
       " 'who': 163839,\n",
       " 'turn': 153451,\n",
       " 'chef': 29092,\n",
       " 'message': 88915,\n",
       " 'passed': 106810,\n",
       " 'back': 15551,\n",
       " 'she': 125823,\n",
       " 'appologized': 11345,\n",
       " 'ordred': 103472,\n",
       " '12oz': 452,\n",
       " 'new': 94605,\n",
       " 'york': 168415,\n",
       " 'strip': 134677,\n",
       " 'ala': 4282,\n",
       " 'carte': 27298,\n",
       " '29': 1018,\n",
       " '95': 1729,\n",
       " 'oz': 105792,\n",
       " 'pure': 114275,\n",
       " 'fat': 50371,\n",
       " 'price': 112767,\n",
       " 'expect': 48513,\n",
       " 'meat': 88038,\n",
       " 'than': 139224,\n",
       " 'ordered': 103208,\n",
       " 'wild': 164385,\n",
       " 'mushroom': 92151,\n",
       " 'pizza': 109692,\n",
       " 'ok': 100106,\n",
       " 'needs': 94196,\n",
       " 'an': 6565,\n",
       " 'over': 105066,\n",
       " 'haul': 65207,\n",
       " 'major': 85577,\n",
       " 'way': 160696,\n",
       " 'if': 71014,\n",
       " 'want': 158629,\n",
       " 'make': 85599,\n",
       " 'any': 10457,\n",
       " 'money': 90554,\n",
       " 'at': 13835,\n",
       " 'saturday': 122253,\n",
       " 'night': 95251,\n",
       " '7pm': 1622,\n",
       " 'empty': 45784,\n",
       " 'think': 146751,\n",
       " 'highlight': 67961,\n",
       " 'meal': 87756,\n",
       " 'bottle': 22181,\n",
       " 'cabinet': 25581,\n",
       " 'totally dissapointed': 151693,\n",
       " 'dissapointed had': 41423,\n",
       " 'had purchased': 63770,\n",
       " 'purchased coupon': 114244,\n",
       " 'coupon from': 34931,\n",
       " 'from travelzoo': 57191,\n",
       " 'travelzoo to': 152391,\n",
       " 'to try': 150437,\n",
       " 'try out': 153196,\n",
       " 'out this': 104774,\n",
       " 'restaurant which': 118600,\n",
       " 'which given': 163438,\n",
       " 'given its': 59586,\n",
       " 'its location': 76631,\n",
       " 'location would': 83559,\n",
       " 'would have': 167191,\n",
       " 'have thought': 65817,\n",
       " 'thought it': 147771,\n",
       " 'it was': 76302,\n",
       " 'was going': 159449,\n",
       " 'going to': 60234,\n",
       " 'to be': 149124,\n",
       " 'be very': 17770,\n",
       " 'very upscale': 157264,\n",
       " 'upscale and': 155382,\n",
       " 'and we': 9871,\n",
       " 'we were': 161186,\n",
       " 'were expecting': 162184,\n",
       " 'expecting whole': 48631,\n",
       " 'whole lot': 164109,\n",
       " 'lot more': 84174,\n",
       " 'more the': 91091,\n",
       " 'the service': 143540,\n",
       " 'service was': 125235,\n",
       " 'was great': 159456,\n",
       " 'great but': 61728,\n",
       " 'but the': 24902,\n",
       " 'the food': 141839,\n",
       " 'food not': 53787,\n",
       " 'not worth': 96916,\n",
       " 'worth it': 167078,\n",
       " 'it the': 76226,\n",
       " 'the restaurant': 143327,\n",
       " 'restaurant itself': 118501,\n",
       " 'itself is': 76716,\n",
       " 'is very': 75227,\n",
       " 'very outdated': 157152,\n",
       " 'outdated very': 104831,\n",
       " 'very 80': 156939,\n",
       " '80 my': 1641,\n",
       " 'and had': 8142,\n",
       " 'had the': 63877,\n",
       " 'the crab': 141339,\n",
       " 'crab cakes': 35279,\n",
       " 'cakes for': 25794,\n",
       " 'for appertizer': 54171,\n",
       " 'appertizer they': 11143,\n",
       " 'they were': 146485,\n",
       " 'were cold': 162103,\n",
       " 'cold when': 31838,\n",
       " 'when they': 163195,\n",
       " 'were served': 162432,\n",
       " 'served we': 124835,\n",
       " 'we told': 161160,\n",
       " 'told our': 150809,\n",
       " 'our waiter': 104462,\n",
       " 'waiter who': 158235,\n",
       " 'who in': 163929,\n",
       " 'in turn': 72464,\n",
       " 'turn told': 153470,\n",
       " 'told the': 150814,\n",
       " 'the chef': 141110,\n",
       " 'chef and': 29094,\n",
       " 'and the': 9635,\n",
       " 'the message': 142630,\n",
       " 'message was': 88922,\n",
       " 'was passed': 159778,\n",
       " 'passed back': 106811,\n",
       " 'back to': 15720,\n",
       " 'to us': 150463,\n",
       " 'us that': 155650,\n",
       " 'that she': 140242,\n",
       " 'she appologized': 125837,\n",
       " 'appologized my': 11346,\n",
       " 'husband ordred': 70741,\n",
       " 'ordred 12oz': 103473,\n",
       " '12oz new': 455,\n",
       " 'new york': 94820,\n",
       " 'york strip': 168426,\n",
       " 'strip ala': 134678,\n",
       " 'ala carte': 4285,\n",
       " 'carte for': 27300,\n",
       " 'for 29': 54115,\n",
       " '29 95': 1019,\n",
       " '95 oz': 1742,\n",
       " 'oz of': 105796,\n",
       " 'of that': 99287,\n",
       " 'that was': 140388,\n",
       " 'was pure': 159844,\n",
       " 'pure fat': 114284,\n",
       " 'fat and': 50373,\n",
       " 'and for': 7978,\n",
       " 'the price': 143162,\n",
       " 'price you': 112864,\n",
       " 'you would': 168951,\n",
       " 'would expect': 167173,\n",
       " 'expect to': 48549,\n",
       " 'to get': 149593,\n",
       " 'get more': 58879,\n",
       " 'more meat': 90990,\n",
       " 'meat than': 88141,\n",
       " 'than fat': 139312,\n",
       " 'fat ordered': 50398,\n",
       " 'ordered wild': 103373,\n",
       " 'wild mushroom': 164389,\n",
       " 'mushroom pizza': 92166,\n",
       " 'pizza which': 109844,\n",
       " 'which was': 163548,\n",
       " 'was ok': 159733,\n",
       " 'ok this': 100156,\n",
       " 'place needs': 110075,\n",
       " 'needs an': 94197,\n",
       " 'an over': 6867,\n",
       " 'over haul': 105138,\n",
       " 'haul in': 65210,\n",
       " 'in major': 72081,\n",
       " 'major way': 85592,\n",
       " 'way if': 160744,\n",
       " 'if they': 71135,\n",
       " 'they want': 146475,\n",
       " 'want to': 158727,\n",
       " 'to make': 149826,\n",
       " 'make any': 85605,\n",
       " 'any money': 10561,\n",
       " 'money at': 90559,\n",
       " 'at the': 14303,\n",
       " 'which for': 163433,\n",
       " 'for saturday': 54859,\n",
       " 'saturday night': 122271,\n",
       " 'night at': 95266,\n",
       " 'at 7pm': 13881,\n",
       " '7pm when': 1626,\n",
       " 'when we': 163217,\n",
       " 'went was': 162012,\n",
       " 'was empty': 159337,\n",
       " 'empty think': 45813,\n",
       " 'think the': 146844,\n",
       " 'the highlight': 142138,\n",
       " 'highlight of': 67963,\n",
       " 'the meal': 142592,\n",
       " 'meal was': 87867,\n",
       " 'was the': 160088,\n",
       " 'the bottle': 140875,\n",
       " 'bottle of': 22194,\n",
       " 'of cabinet': 98043,\n",
       " 'costco': 34452,\n",
       " 'travel': 152335,\n",
       " 'recently': 116752,\n",
       " 'returned': 118832,\n",
       " 'trip': 152771,\n",
       " 'big': 20378,\n",
       " 'island': 75308,\n",
       " 'hi': 67805,\n",
       " 'arranged': 12660,\n",
       " 'throught': 148072,\n",
       " 'shopping': 126512,\n",
       " 'around': 12517,\n",
       " 'found': 55371,\n",
       " 'their': 144421,\n",
       " 'prices': 112931,\n",
       " 'phone': 109000,\n",
       " 'able': 1851,\n",
       " 'all': 4413,\n",
       " 'arrangements': 12669,\n",
       " 'airfair': 4157,\n",
       " 'condo': 33130,\n",
       " 'car': 26795,\n",
       " 'didn': 39961,\n",
       " 'with': 165036,\n",
       " 'bs': 23604,\n",
       " 'on': 100462,\n",
       " 'hilo': 68062,\n",
       " 'adjust': 3090,\n",
       " 'dates': 37411,\n",
       " 'according': 2478,\n",
       " 'plan': 110344,\n",
       " 'being': 19147,\n",
       " 'accurate': 2507,\n",
       " 'outstanding': 104994,\n",
       " 'value': 156217,\n",
       " 'gas': 58261,\n",
       " 'did': 39819,\n",
       " 'some': 129898,\n",
       " 'souvenier': 131134,\n",
       " 'kona': 79350,\n",
       " 'again': 3739,\n",
       " 'saved': 122548,\n",
       " 've': 156401,\n",
       " 'shopped': 126497,\n",
       " 'years': 167877,\n",
       " 'becoming': 18288,\n",
       " 'groupie': 62694,\n",
       " 'costco travel': 34461,\n",
       " 'travel my': 152346,\n",
       " 'and recently': 9076,\n",
       " 'recently returned': 116779,\n",
       " 'returned from': 118836,\n",
       " 'from trip': 57192,\n",
       " 'trip to': 152818,\n",
       " 'to the': 150391,\n",
       " 'the big': 140801,\n",
       " 'big island': 20443,\n",
       " 'island hi': 75311,\n",
       " 'hi that': 67812,\n",
       " 'that we': 140393,\n",
       " 'we arranged': 160848,\n",
       " 'arranged throught': 12663,\n",
       " 'throught costco': 148073,\n",
       " 'travel after': 152336,\n",
       " 'after shopping': 3608,\n",
       " 'shopping around': 126517,\n",
       " 'around found': 12574,\n",
       " 'found that': 55457,\n",
       " 'that their': 140328,\n",
       " 'their prices': 144882,\n",
       " 'prices were': 113005,\n",
       " 'were the': 162489,\n",
       " 'the best': 140788,\n",
       " 'best and': 19639,\n",
       " 'and after': 6989,\n",
       " 'after one': 3569,\n",
       " 'one phone': 101374,\n",
       " 'phone call': 109012,\n",
       " 'call was': 25924,\n",
       " 'was able': 159030,\n",
       " 'able to': 1853,\n",
       " 'make all': 85602,\n",
       " 'all arrangements': 4435,\n",
       " 'arrangements for': 12671,\n",
       " 'for airfair': 54145,\n",
       " 'airfair condo': 4158,\n",
       " 'condo and': 33131,\n",
       " 'and car': 7353,\n",
       " 'car they': 26850,\n",
       " 'they didn': 146199,\n",
       " 'didn have': 40006,\n",
       " 'have arrangements': 65267,\n",
       " 'arrangements with': 12674,\n",
       " 'with any': 165074,\n",
       " 'any bs': 10475,\n",
       " 'bs on': 23609,\n",
       " 'on hilo': 100708,\n",
       " 'hilo but': 68063,\n",
       " 'but were': 24956,\n",
       " 'were able': 162029,\n",
       " 'to adjust': 149027,\n",
       " 'adjust our': 3092,\n",
       " 'our travel': 104441,\n",
       " 'travel dates': 152342,\n",
       " 'dates everything': 37415,\n",
       " 'everything went': 47995,\n",
       " 'went according': 161948,\n",
       " 'according to': 2480,\n",
       " 'to plan': 150016,\n",
       " 'plan with': 110366,\n",
       " 'with all': 165061,\n",
       " 'arrangements being': 12670,\n",
       " 'being accurate': 19151,\n",
       " 'accurate condo': 2509,\n",
       " 'condo was': 33133,\n",
       " 'was outstanding': 159755,\n",
       " 'outstanding and': 104998,\n",
       " 'and great': 8106,\n",
       " 'great value': 62146,\n",
       " 'value we': 156244,\n",
       " 'we got': 160964,\n",
       " 'got gas': 61068,\n",
       " 'gas and': 58262,\n",
       " 'and did': 7687,\n",
       " 'did some': 39922,\n",
       " 'some souvenier': 130227,\n",
       " 'souvenier shopping': 131135,\n",
       " 'shopping at': 126519,\n",
       " 'the costco': 141314,\n",
       " 'costco in': 34459,\n",
       " 'in kona': 72032,\n",
       " 'kona and': 79351,\n",
       " 'and again': 6992,\n",
       " 'again saved': 3834,\n",
       " 'saved ve': 122559,\n",
       " 've shopped': 156503,\n",
       " 'shopped at': 126498,\n",
       " 'at costco': 13980,\n",
       " 'costco for': 34457,\n",
       " 'for years': 55095,\n",
       " 'years now': 167931,\n",
       " 'now becoming': 97203,\n",
       " 'becoming groupie': 18290,\n",
       " 'been': 18450,\n",
       " 'couple': 34863,\n",
       " 'there': 145636,\n",
       " 'advantages': 3244,\n",
       " 'rarely': 115431,\n",
       " 'busy': 24426,\n",
       " 'larger': 79926,\n",
       " 'groups': 62716,\n",
       " 'last': 79993,\n",
       " 'few': 51273,\n",
       " 'times': 148627,\n",
       " 'experienced': 48822,\n",
       " 'average': 14951,\n",
       " 'lousy': 84307,\n",
       " 'joining': 77376,\n",
       " 'already': 5034,\n",
       " 'seated': 123664,\n",
       " 'group': 62658,\n",
       " '28': 1013,\n",
       " 'high': 67861,\n",
       " 'school': 123082,\n",
       " 'hostess': 69442,\n",
       " 'wagged': 158032,\n",
       " 'her': 67138,\n",
       " 'finger': 52120,\n",
       " 'face': 49417,\n",
       " 'like': 81588,\n",
       " 'east': 44527,\n",
       " 'german': 58660,\n",
       " 'border': 21942,\n",
       " 'guard': 62851,\n",
       " 'waffle': 157998,\n",
       " 'house': 69898,\n",
       " 'waitress': 158283,\n",
       " 'poked': 111160,\n",
       " 'shoulder': 126751,\n",
       " 'attention': 14605,\n",
       " 'wife': 164298,\n",
       " 'chicken': 29320,\n",
       " 'dish': 41138,\n",
       " 'sent': 124556,\n",
       " 'as': 12924,\n",
       " 'measly': 88023,\n",
       " 'pieces': 109374,\n",
       " 'beers': 18837,\n",
       " 'tap': 137782,\n",
       " 'garbage': 58132,\n",
       " 'not good': 96536,\n",
       " 'and it': 8330,\n",
       " 'it not': 75988,\n",
       " 'not been': 96343,\n",
       " 'been for': 18546,\n",
       " 'for couple': 54321,\n",
       " 'couple of': 34888,\n",
       " 'of years': 99458,\n",
       " 'years there': 167955,\n",
       " 'there are': 145661,\n",
       " 'are advantages': 11548,\n",
       " 'advantages good': 3245,\n",
       " 'good location': 60600,\n",
       " 'location rarely': 83527,\n",
       " 'rarely busy': 115432,\n",
       " 'busy good': 24447,\n",
       " 'good for': 60523,\n",
       " 'for larger': 54588,\n",
       " 'larger groups': 79931,\n",
       " 'groups but': 62718,\n",
       " 'but last': 24726,\n",
       " 'last few': 80016,\n",
       " 'few times': 51407,\n",
       " 'times we': 148722,\n",
       " 'we ve': 161171,\n",
       " 've been': 156411,\n",
       " 'been there': 18712,\n",
       " 'there have': 145750,\n",
       " 'have experienced': 65420,\n",
       " 'experienced average': 48828,\n",
       " 'average food': 14959,\n",
       " 'food and': 53569,\n",
       " 'and lousy': 8499,\n",
       " 'lousy service': 84311,\n",
       " 'service when': 125242,\n",
       " 'when joining': 163097,\n",
       " 'joining my': 77377,\n",
       " 'my already': 92429,\n",
       " 'already seated': 5086,\n",
       " 'seated group': 123674,\n",
       " 'group on': 62679,\n",
       " 'on saturday': 100889,\n",
       " 'saturday 28': 122254,\n",
       " '28 the': 1015,\n",
       " 'the high': 142134,\n",
       " 'high school': 67915,\n",
       " 'school hostess': 123099,\n",
       " 'hostess wagged': 69472,\n",
       " 'wagged her': 158033,\n",
       " 'her finger': 67223,\n",
       " 'finger in': 52122,\n",
       " 'my face': 92727,\n",
       " 'face like': 49442,\n",
       " 'like an': 81613,\n",
       " 'an east': 6666,\n",
       " 'east german': 44537,\n",
       " 'german border': 58665,\n",
       " 'border guard': 21946,\n",
       " 'guard the': 62855,\n",
       " 'the waffle': 144221,\n",
       " 'waffle house': 158002,\n",
       " 'house waitress': 69988,\n",
       " 'waitress poked': 158319,\n",
       " 'poked me': 111161,\n",
       " 'me in': 87514,\n",
       " 'in the': 72415,\n",
       " 'the shoulder': 143592,\n",
       " 'shoulder to': 126757,\n",
       " 'get my': 58882,\n",
       " 'my attention': 92455,\n",
       " 'attention and': 14606,\n",
       " 'the wife': 144289,\n",
       " 'wife chicken': 164305,\n",
       " 'chicken dish': 29367,\n",
       " 'dish had': 41164,\n",
       " 'had to': 63889,\n",
       " 'be sent': 17682,\n",
       " 'sent back': 124557,\n",
       " 'back as': 15564,\n",
       " 'as there': 13314,\n",
       " 'there were': 145921,\n",
       " 'were only': 162345,\n",
       " 'only measly': 101823,\n",
       " 'measly pieces': 88026,\n",
       " 'pieces of': 109388,\n",
       " 'of chicken': 98105,\n",
       " 'chicken in': 29389,\n",
       " 'in it': 72014,\n",
       " 'it only': 76007,\n",
       " 'only beers': 101677,\n",
       " 'beers on': 18855,\n",
       " 'on tap': 100954,\n",
       " 'tap garbage': 137787,\n",
       " 'muffler': 92040,\n",
       " 'shop': 126413,\n",
       " 'town': 151917,\n",
       " 'shops': 126544,\n",
       " 'trust': 153077,\n",
       " 'mighty': 89296,\n",
       " 'them': 145081,\n",
       " 'greg': 62349,\n",
       " 'has': 64833,\n",
       " 'worked': 166764,\n",
       " 'multiple': 92068,\n",
       " 'cars': 27276,\n",
       " 'done': 42460,\n",
       " 'job': 77218,\n",
       " 'ever': 47519,\n",
       " 'issues': 75440,\n",
       " 'he': 66072,\n",
       " 'takes': 137492,\n",
       " 'care': 26991,\n",
       " 'problem': 113305,\n",
       " 'no': 95498,\n",
       " 'questions': 114734,\n",
       " 'asked': 13539,\n",
       " 'best muffler': 19828,\n",
       " 'muffler shop': 92042,\n",
       " 'shop in': 126447,\n",
       " 'in town': 72454,\n",
       " 'town there': 152009,\n",
       " 'are very': 12155,\n",
       " 'very few': 157047,\n",
       " 'few shops': 51389,\n",
       " 'shops that': 126562,\n",
       " 'that trust': 140361,\n",
       " 'trust and': 153078,\n",
       " 'and mighty': 8607,\n",
       " 'mighty muffler': 89297,\n",
       " 'muffler is': 92041,\n",
       " 'is one': 74876,\n",
       " 'of them': 99293,\n",
       " 'them greg': 145172,\n",
       " 'greg has': 62351,\n",
       " 'has worked': 65109,\n",
       " 'worked on': 166774,\n",
       " 'on multiple': 100785,\n",
       " 'multiple cars': 92070,\n",
       " 'cars and': 27277,\n",
       " 'and has': 8167,\n",
       " 'has always': 64844,\n",
       " 'always done': 5589,\n",
       " 'done great': 42490,\n",
       " 'great job': 61903,\n",
       " 'job if': 77242,\n",
       " 'if there': 71133,\n",
       " 'there is': 145765,\n",
       " 'is ever': 74522,\n",
       " 'ever any': 47527,\n",
       " 'any issues': 10541,\n",
       " 'issues he': 75451,\n",
       " 'he takes': 66284,\n",
       " 'takes care': 137500,\n",
       " 'care of': 27026,\n",
       " 'the problem': 143174,\n",
       " 'problem no': 113329,\n",
       " 'no questions': 95771,\n",
       " 'questions asked': 114738,\n",
       " 'just': 77704,\n",
       " 'start': 133078,\n",
       " 'off': 99473,\n",
       " 'by': 25236,\n",
       " 'saying': 122816,\n",
       " 'egg': 45133,\n",
       " 'salad': 121162,\n",
       " 'sandwiches': 121997,\n",
       " 'probably': 113217,\n",
       " 'tried': 152634,\n",
       " 'sandwich': 121896,\n",
       " 'anywhere': 10907,\n",
       " 'serves': 124979,\n",
       " 'sacks': 120902,\n",
       " 'far': 50161,\n",
       " 'entitled': 46522,\n",
       " 'dali': 37103,\n",
       " 'life': 81379,\n",
       " 'live': 82941,\n",
       " 'north': 96224,\n",
       " 'will': 164417,\n",
       " 'literally': 82554,\n",
       " 'many': 86251,\n",
       " 'miles': 89363,\n",
       " 'eat': 44596,\n",
       " 'top': 151376,\n",
       " 'wonderful': 166398,\n",
       " 'menu': 88642,\n",
       " 'whenever': 163226,\n",
       " 'order': 103028,\n",
       " 'comes': 32187,\n",
       " 'little': 82616,\n",
       " 'cookie': 33888,\n",
       " 'cookies': 33922,\n",
       " 'can': 26218,\n",
       " 'purchase': 114209,\n",
       " 'dough': 42824,\n",
       " 'also': 5119,\n",
       " 'other': 103691,\n",
       " 'delicious': 38629,\n",
       " 'dessert': 39503,\n",
       " 'bars': 16782,\n",
       " 'salads': 121287,\n",
       " 'sale': 121344,\n",
       " 'well': 161717,\n",
       " 'eating': 44803,\n",
       " 'least': 80538,\n",
       " '14': 486,\n",
       " 'hope': 69186,\n",
       " 'never': 94416,\n",
       " 'go': 59897,\n",
       " 'away': 15079,\n",
       " 'would just': 167199,\n",
       " 'just like': 77939,\n",
       " 'like to': 82039,\n",
       " 'to start': 150324,\n",
       " 'start off': 133114,\n",
       " 'off by': 99499,\n",
       " 'by saying': 25438,\n",
       " 'saying that': 122832,\n",
       " 'that love': 140029,\n",
       " 'love egg': 84377,\n",
       " 'egg salad': 45163,\n",
       " 'salad sandwiches': 121246,\n",
       " 'sandwiches have': 122015,\n",
       " 'have probably': 65676,\n",
       " 'probably tried': 113294,\n",
       " 'tried an': 152640,\n",
       " 'an egg': 6673,\n",
       " 'salad sandwich': 121245,\n",
       " 'sandwich anywhere': 121907,\n",
       " 'anywhere that': 10932,\n",
       " 'that serves': 140236,\n",
       " 'serves egg': 124987,\n",
       " 'salad sacks': 121243,\n",
       " 'sacks is': 120903,\n",
       " 'is by': 74343,\n",
       " 'by far': 25305,\n",
       " 'far the': 50209,\n",
       " 'best egg': 19744,\n",
       " 'sandwich entitled': 121919,\n",
       " 'entitled the': 46523,\n",
       " 'the dali': 141405,\n",
       " 'dali have': 37104,\n",
       " 'have ever': 65411,\n",
       " 'ever had': 47570,\n",
       " 'had in': 63615,\n",
       " 'my life': 92951,\n",
       " 'life live': 81413,\n",
       " 'live in': 82966,\n",
       " 'in north': 72147,\n",
       " 'north phoenix': 96239,\n",
       " 'phoenix and': 108851,\n",
       " 'and will': 9911,\n",
       " 'will literally': 164518,\n",
       " 'literally drive': 82567,\n",
       " 'drive many': 43642,\n",
       " 'many miles': 86334,\n",
       " 'miles just': 89375,\n",
       " 'just to': 78130,\n",
       " 'to eat': 149447,\n",
       " 'eat at': 44607,\n",
       " 'at sacks': 14236,\n",
       " 'sacks on': 120905,\n",
       " 'on top': 100994,\n",
       " 'top of': 151417,\n",
       " 'the wonderful': 144322,\n",
       " 'wonderful menu': 166462,\n",
       " 'menu whenever': 88785,\n",
       " 'whenever you': 163247,\n",
       " 'you order': 168750,\n",
       " ...}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that accepts a vectorizer and calculates the accuracy\n",
    "def tokenize_test(vect):\n",
    "    X_train_dtm = vect.fit_transform(X_train)\n",
    "    print('Features: ', X_train_dtm.shape[1])\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train_dtm, y_train)\n",
    "    y_pred_class = nb.predict(X_test_dtm)\n",
    "    print('Accuracy: ', metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  169847\n",
      "Accuracy:  0.854207436399\n"
     ]
    }
   ],
   "source": [
    "# include 1-grams and 2-grams\n",
    "vect = CountVectorizer(ngram_range=(1, 2))\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Stopword Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **What:** Remove common words that will likely appear in any text\n",
    "- **Why:** They don't tell you much about your text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Recreate your features with CountVectorizer removing stopwords.\n",
    "\n",
    "- **stop_words:** string {'english'}, list, or None (default)\n",
    "- If 'english', a built-in stop word list for English is used.\n",
    "- If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens.\n",
    "- If None, no stop words will be used. max_df can be set to a value in the range [0.7, 1.0) to automatically detect and filter stop words based on intra corpus document frequency of terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show vectorizer options\n",
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove English stop words\n",
    "vect = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Validate your model using the features with stopwords removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  16528\n",
      "Accuracy:  0.915851272016\n"
     ]
    }
   ],
   "source": [
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'how', 'fifty', 'get', 'her', 'take', 'myself', 'what', 'whom', 'whose', 'further', 'without', 'off', 're', 'anyone', 'still', 'more', 'he', 'toward', 'over', 'them', 'describe', 'my', 'might', 'therefore', 'amount', 'by', 'hereby', 'eleven', 'may', 'same', 'whoever', 'became', 'front', 'always', 'empty', 'ie', 'ours', 'own', 'towards', 'however', 'hasnt', 'never', 'anyway', 'of', 'now', 'our', 'seeming', 'rather', 'whenever', 'thereby', 'an', 'hers', 'see', 'its', 'even', 'some', 'us', 'after', 'find', 'name', 'whereupon', 'between', 'serious', 'thus', 'ourselves', 'too', 'someone', 'seems', 'because', 'the', 'in', 'whence', 'his', 'both', 'yourself', 'that', 'yourselves', 'and', 'you', 'when', 'seemed', 'a', 'but', 'itself', 'enough', 'have', 'per', 'against', 'eg', 'once', 'hereafter', 'almost', 'fill', 'upon', 'next', 'below', 'from', 'who', 'six', 'should', 'becomes', 'other', 'three', 'nobody', 'again', 'side', 'each', 'hundred', 'seem', 'whereby', 'ever', 'well', 'one', 'than', 'top', 'down', 'somewhere', 'me', 'thin', 'their', 'wherein', 'which', 'due', 'had', 'being', 'cant', 'was', 'whereas', 'sometimes', 'please', 'on', 'two', 'elsewhere', 'ltd', 'until', 'back', 'thence', 'first', 'less', 'into', 'often', 'only', 'whether', 'within', 'before', 'could', 'must', 'except', 'has', 'neither', 'or', 'several', 'across', 'something', 'thick', 'inc', 'twelve', 'herein', 'de', 'made', 'him', 'everyone', 'five', 'onto', 'were', 'herself', 'do', 'nevertheless', 'last', 'fifteen', 'whole', 'already', 'although', 'fire', 'become', 'couldnt', 'though', 'anywhere', 'nor', 'since', 'very', 'behind', 'somehow', 'anyhow', 'out', 'un', 'we', 'alone', 'bottom', 'themselves', 'anything', 'together', 'with', 'move', 'wherever', 'co', 'detail', 'am', 'every', 'not', 'these', 'mostly', 'none', 'namely', 'either', 'thru', 'cry', 'amongst', 'former', 'therein', 'whereafter', 'then', 'part', 'done', 'while', 'yet', 'are', 'keep', 'about', 'been', 'can', 'amoungst', 'so', 'go', 'for', 'under', 'thereafter', 'along', 'sometime', 'any', 'at', 'otherwise', 'another', 'would', 'perhaps', 'yours', 'beyond', 'if', 'here', 'least', 'as', 'full', 'to', 'via', 'con', 'beforehand', 'this', 'during', 'everything', 'give', 'hence', 'meanwhile', 'above', 'nowhere', 'ten', 'four', 'also', 'sincere', 'himself', 'why', 'third', 'besides', 'those', 'up', 'be', 'formerly', 'found', 'sixty', 'where', 'becoming', 'mill', 'it', 'is', 'throughout', 'beside', 'cannot', 'noone', 'call', 'twenty', 'latterly', 'indeed', 'nothing', 'system', 'your', 'she', 'bill', 'others', 'etc', 'most', 'they', 'show', 'everywhere', 'around', 'nine', 'there', 'will', 'forty', 'afterwards', 'hereupon', 'moreover', 'such', 'interest', 'many', 'else', 'i', 'put', 'mine', 'thereupon', 'among', 'latter', 'through', 'no', 'whither', 'all', 'much', 'whatever', 'eight', 'few'})\n"
     ]
    }
   ],
   "source": [
    "# set of stop words\n",
    "print(vect.get_stop_words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Other CountVectorizer Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Shrink the maximum number of features and re-test the model.\n",
    "\n",
    "- **max_features:** int or None, default=None\n",
    "- If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  100\n",
      "Accuracy:  0.869863013699\n"
     ]
    }
   ],
   "source": [
    "# remove English stop words and only keep 100 features\n",
    "vect = CountVectorizer(stop_words='english', max_features=100)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'amazing', u'area', u'atmosphere', u'awesome', u'bad', u'bar', u'best', u'better', u'big', u'came', u'cheese', u'chicken', u'clean', u'coffee', u'come', u'day', u'definitely', u'delicious', u'did', u'didn', u'dinner', u'don', u'eat', u'excellent', u'experience', u'favorite', u'feel', u'food', u'free', u'fresh', u'friendly', u'friends', u'going', u'good', u'got', u'great', u'happy', u'home', u'hot', u'hour', u'just', u'know', u'like', u'little', u'll', u'location', u'long', u'looking', u'lot', u'love', u'lunch', u'make', u'meal', u'menu', u'minutes', u'need', u'new', u'nice', u'night', u'order', u'ordered', u'people', u'perfect', u'phoenix', u'pizza', u'place', u'pretty', u'prices', u'really', u'recommend', u'restaurant', u'right', u'said', u'salad', u'sandwich', u'sauce', u'say', u'service', u'staff', u'store', u'sure', u'table', u'thing', u'things', u'think', u'time', u'times', u'took', u'town', u'tried', u'try', u've', u'wait', u'want', u'way', u'went', u'wine', u'work', u'worth', u'years']\n"
     ]
    }
   ],
   "source": [
    "# all 100 features\n",
    "print(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  169847\n",
      "Accuracy:  0.854207436399\n"
     ]
    }
   ],
   "source": [
    "# include 1-grams and 2-grams, and limit the number of features\n",
    "vect = CountVectorizer(ngram_range=(1, 2))#, max_features=100000)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  100000\n",
      "Accuracy:  0.901174168297\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(ngram_range=(2, 3), max_features=100000)\n",
    "tokenize_test(vect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Change the minimum document frequency for terms and test the model's performance.\n",
    "\n",
    "- **min_df:** float in range [0.0, 1.0] or int, default=1\n",
    "- When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float, the parameter represents a proportion of documents, integer absolute counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  43957\n",
      "Accuracy:  0.932485322896\n"
     ]
    }
   ],
   "source": [
    "# include 1-grams and 2-grams, and only include terms that appear at least 2 times\n",
    "vect = CountVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Introduction to TextBlob\n",
    "\n",
    "TextBlob: \"Simplified Text Processing\"\n",
    "\n",
    "### 5.1 Use `TextBlob` to convert the text in the first review in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.\n",
      "\n",
      "Do yourself a favor and get their Bloody Mary.  It was phenomenal and simply the best I've ever had.  I'm pretty sure they only use ingredients from their garden and blend them fresh when you order it.  It was amazing.\n",
      "\n",
      "While EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  It was the best \"toast\" I've ever had.\n",
      "\n",
      "Anyway, I can't wait to go back!\n"
     ]
    }
   ],
   "source": [
    "# print the first review\n",
    "print(yelp_best_worst.text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it as a TextBlob object\n",
    "review = TextBlob(yelp_best_worst.text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 List the words in the `TextBlob` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['My', 'wife', 'took', 'me', 'here', 'on', 'my', 'birthday', 'for', 'breakfast', 'and', 'it', 'was', 'excellent', 'The', 'weather', 'was', 'perfect', 'which', 'made', 'sitting', 'outside', 'overlooking', 'their', 'grounds', 'an', 'absolute', 'pleasure', 'Our', 'waitress', 'was', 'excellent', 'and', 'our', 'food', 'arrived', 'quickly', 'on', 'the', 'semi-busy', 'Saturday', 'morning', 'It', 'looked', 'like', 'the', 'place', 'fills', 'up', 'pretty', 'quickly', 'so', 'the', 'earlier', 'you', 'get', 'here', 'the', 'better', 'Do', 'yourself', 'a', 'favor', 'and', 'get', 'their', 'Bloody', 'Mary', 'It', 'was', 'phenomenal', 'and', 'simply', 'the', 'best', 'I', \"'ve\", 'ever', 'had', 'I', \"'m\", 'pretty', 'sure', 'they', 'only', 'use', 'ingredients', 'from', 'their', 'garden', 'and', 'blend', 'them', 'fresh', 'when', 'you', 'order', 'it', 'It', 'was', 'amazing', 'While', 'EVERYTHING', 'on', 'the', 'menu', 'looks', 'excellent', 'I', 'had', 'the', 'white', 'truffle', 'scrambled', 'eggs', 'vegetable', 'skillet', 'and', 'it', 'was', 'tasty', 'and', 'delicious', 'It', 'came', 'with', '2', 'pieces', 'of', 'their', 'griddled', 'bread', 'with', 'was', 'amazing', 'and', 'it', 'absolutely', 'made', 'the', 'meal', 'complete', 'It', 'was', 'the', 'best', 'toast', 'I', \"'ve\", 'ever', 'had', 'Anyway', 'I', 'ca', \"n't\", 'wait', 'to', 'go', 'back'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the words\n",
    "review.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 List the sentences in the `TextBlob` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"My wife took me here on my birthday for breakfast and it was excellent.\"),\n",
       " Sentence(\"The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.\"),\n",
       " Sentence(\"Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.\"),\n",
       " Sentence(\"It looked like the place fills up pretty quickly so the earlier you get here the better.\"),\n",
       " Sentence(\"Do yourself a favor and get their Bloody Mary.\"),\n",
       " Sentence(\"It was phenomenal and simply the best I've ever had.\"),\n",
       " Sentence(\"I'm pretty sure they only use ingredients from their garden and blend them fresh when you order it.\"),\n",
       " Sentence(\"It was amazing.\"),\n",
       " Sentence(\"While EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.\"),\n",
       " Sentence(\"It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.\"),\n",
       " Sentence(\"It was the best \"toast\" I've ever had.\"),\n",
       " Sentence(\"Anyway, I can't wait to go back!\")]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the sentences\n",
    "review.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"my wife took me here on my birthday for breakfast and it was excellent.  the weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  our waitress was excellent and our food arrived quickly on the semi-busy saturday morning.  it looked like the place fills up pretty quickly so the earlier you get here the better.\n",
       "\n",
       "do yourself a favor and get their bloody mary.  it was phenomenal and simply the best i've ever had.  i'm pretty sure they only use ingredients from their garden and blend them fresh when you order it.  it was amazing.\n",
       "\n",
       "while everything on the menu looks excellent, i had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  it came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  it was the best \"toast\" i've ever had.\n",
       "\n",
       "anyway, i can't wait to go back!\")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some string methods are available\n",
    "review.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Stemming and Lemmatization\n",
    "\n",
    "**Stemming:**\n",
    "\n",
    "- **What:** Reduce a word to its base/stem/root form\n",
    "- **Why:** Often makes sense to treat related words the same way\n",
    "- **Notes:**\n",
    "    - Uses a \"simple\" and fast rule-based approach\n",
    "    - Stemmed words are usually not shown to users (used for analysis/indexing)\n",
    "    - Some search engines treat words with the same stem as synonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Initialize the `SnowballStemmer` and stem the words in the first review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'my', u'wife', u'took', u'me', u'here', u'on', u'my', u'birthday', u'for', u'breakfast', u'and', u'it', u'was', u'excel', u'the', u'weather', u'was', u'perfect', u'which', u'made', u'sit', u'outsid', u'overlook', u'their', u'ground', u'an', u'absolut', u'pleasur', u'our', u'waitress', u'was', u'excel', u'and', u'our', u'food', u'arriv', u'quick', u'on', u'the', u'semi-busi', u'saturday', u'morn', u'it', u'look', u'like', u'the', u'place', u'fill', u'up', u'pretti', u'quick', u'so', u'the', u'earlier', u'you', u'get', u'here', u'the', u'better', u'do', u'yourself', u'a', u'favor', u'and', u'get', u'their', u'bloodi', u'mari', u'it', u'was', u'phenomen', u'and', u'simpli', u'the', u'best', u'i', u've', u'ever', u'had', u'i', u\"'m\", u'pretti', u'sure', u'they', u'onli', u'use', u'ingredi', u'from', u'their', u'garden', u'and', u'blend', u'them', u'fresh', u'when', u'you', u'order', u'it', u'it', u'was', u'amaz', u'while', u'everyth', u'on', u'the', u'menu', u'look', u'excel', u'i', u'had', u'the', u'white', u'truffl', u'scrambl', u'egg', u'veget', u'skillet', u'and', u'it', u'was', u'tasti', u'and', u'delici', u'it', u'came', u'with', u'2', u'piec', u'of', u'their', u'griddl', u'bread', u'with', u'was', u'amaz', u'and', u'it', u'absolut', u'made', u'the', u'meal', u'complet', u'it', u'was', u'the', u'best', u'toast', u'i', u've', u'ever', u'had', u'anyway', u'i', u'ca', u\"n't\", u'wait', u'to', u'go', u'back']\n"
     ]
    }
   ],
   "source": [
    "# initialize stemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "# stem each word\n",
    "print([stemmer.stem(word) for word in review.words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Use the built-in `lemmatize` function on the words of the first review (parsed by `TextBlob`)\n",
    "\n",
    "**Lemmatization**\n",
    "\n",
    "- **What:** Derive the canonical form ('lemma') of a word\n",
    "- **Why:** Can be better than stemming\n",
    "- **Notes:** Uses a dictionary-based approach (slower than stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'wife', 'took', 'me', 'here', 'on', 'my', 'birthday', 'for', 'breakfast', 'and', 'it', u'wa', 'excellent', 'The', 'weather', u'wa', 'perfect', 'which', 'made', 'sitting', 'outside', 'overlooking', 'their', u'ground', 'an', 'absolute', 'pleasure', 'Our', 'waitress', u'wa', 'excellent', 'and', 'our', 'food', 'arrived', 'quickly', 'on', 'the', 'semi-busy', 'Saturday', 'morning', 'It', 'looked', 'like', 'the', 'place', u'fill', 'up', 'pretty', 'quickly', 'so', 'the', 'earlier', 'you', 'get', 'here', 'the', 'better', 'Do', 'yourself', 'a', 'favor', 'and', 'get', 'their', 'Bloody', 'Mary', 'It', u'wa', 'phenomenal', 'and', 'simply', 'the', 'best', 'I', \"'ve\", 'ever', 'had', 'I', \"'m\", 'pretty', 'sure', 'they', 'only', 'use', u'ingredient', 'from', 'their', 'garden', 'and', 'blend', 'them', 'fresh', 'when', 'you', 'order', 'it', 'It', u'wa', 'amazing', 'While', 'EVERYTHING', 'on', 'the', 'menu', u'look', 'excellent', 'I', 'had', 'the', 'white', 'truffle', 'scrambled', u'egg', 'vegetable', 'skillet', 'and', 'it', u'wa', 'tasty', 'and', 'delicious', 'It', 'came', 'with', '2', u'piece', 'of', 'their', 'griddled', 'bread', 'with', u'wa', 'amazing', 'and', 'it', 'absolutely', 'made', 'the', 'meal', 'complete', 'It', u'wa', 'the', 'best', 'toast', 'I', \"'ve\", 'ever', 'had', 'Anyway', 'I', 'ca', \"n't\", 'wait', 'to', 'go', 'back']\n"
     ]
    }
   ],
   "source": [
    "# assume every word is a noun\n",
    "print([word.lemmatize() for word in review.words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'wife', u'take', 'me', 'here', 'on', 'my', 'birthday', 'for', 'breakfast', 'and', 'it', u'be', 'excellent', 'The', 'weather', u'be', 'perfect', 'which', u'make', u'sit', 'outside', u'overlook', 'their', u'ground', 'an', 'absolute', 'pleasure', 'Our', 'waitress', u'be', 'excellent', 'and', 'our', 'food', u'arrive', 'quickly', 'on', 'the', 'semi-busy', 'Saturday', 'morning', 'It', u'look', 'like', 'the', 'place', u'fill', 'up', 'pretty', 'quickly', 'so', 'the', 'earlier', 'you', 'get', 'here', 'the', 'better', 'Do', 'yourself', 'a', 'favor', 'and', 'get', 'their', 'Bloody', 'Mary', 'It', u'be', 'phenomenal', 'and', 'simply', 'the', 'best', 'I', \"'ve\", 'ever', u'have', 'I', \"'m\", 'pretty', 'sure', 'they', 'only', 'use', 'ingredients', 'from', 'their', 'garden', 'and', 'blend', 'them', 'fresh', 'when', 'you', 'order', 'it', 'It', u'be', u'amaze', 'While', 'EVERYTHING', 'on', 'the', 'menu', u'look', 'excellent', 'I', u'have', 'the', 'white', 'truffle', u'scramble', u'egg', 'vegetable', 'skillet', 'and', 'it', u'be', 'tasty', 'and', 'delicious', 'It', u'come', 'with', '2', u'piece', 'of', 'their', u'griddle', 'bread', 'with', u'be', u'amaze', 'and', 'it', 'absolutely', u'make', 'the', 'meal', 'complete', 'It', u'be', 'the', 'best', 'toast', 'I', \"'ve\", 'ever', u'have', 'Anyway', 'I', 'ca', \"n't\", 'wait', 'to', 'go', 'back']\n"
     ]
    }
   ],
   "source": [
    "# assume every word is a verb\n",
    "print([word.lemmatize(pos='v') for word in review.words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Write a function that uses `TextBlob` and `lemmatize` to lemmatize text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that accepts text and returns a list of lemmas\n",
    "def split_into_lemmas(text):\n",
    "    text = str(text, 'utf-8').lower()\n",
    "    words = TextBlob(text).words\n",
    "    return [word.lemmatize() for word in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Provide your function to `CountVectorizer` as the `analyzer` and test the performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  16452\n",
      "Accuracy:  0.920743639922\n"
     ]
    }
   ],
   "source": [
    "# use split_into_lemmas as the feature extraction function (WARNING: SLOW!)\n",
    "vect = CountVectorizer(analyzer=split_into_lemmas)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'yuyuyummy', u'yuzu', u'z', u'z-grill', u'z11', u'zach', u'zam', u'zanella', u'zankou', u'zappos', u'zatsiki', u'zen', u'zen-like', u'zero', u'zero-star', u'zest', u'zexperience', u'zha', u'zhou', u'zia', u'zilch', u'zin', u'zinburger', u'zinburgergeist', u'zinc', u'zinfandel', u'zing', u'zip', u'zipcar', u'zipper', u'zipps', u'ziti', u'zoe', u'zombi', u'zombie', u'zone', u'zoning', u'zoo', u'zoyo', u'zucca', u'zucchini', u'zuchinni', u'zumba', u'zupa', u'zuzu', u'zwiebel-kr\\xe4uter', u'zzed', u'\\xe9clairs', u'\\xe9cole', u'\\xe9m']\n"
     ]
    }
   ],
   "source": [
    "# last 50 features\n",
    "print(vect.get_feature_names()[-50:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "- **What:** Computes \"relative frequency\" that a word appears in a document compared to its frequency across all documents\n",
    "- **Why:** More useful than \"term frequency\" for identifying \"important\" words in each document (high frequency in that document, low frequency in other documents)\n",
    "- **Notes:** Used for search engine scoring, text summarization, document clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Build a simple TF-IDF using CountVectorizer\n",
    "\n",
    "- Term Frequency can be calulated with default CountVectorizer.\n",
    "- Inverse Document Frequency can be calculated with CountVectorizer and argument `binary=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More details:** [TF-IDF is about what matters](http://planspace.org/20150524-tfidf_is_about_what_matters/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example documents\n",
    "simple_train = ['call you tonight', 'Call me a cab', 'please call me... PLEASE!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   0       0        1    1\n",
       "1    1     1   1       0        0    0\n",
       "2    0     1   1       2        0    0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Term Frequency\n",
    "vect = CountVectorizer()\n",
    "tf = pd.DataFrame(vect.fit_transform(simple_train).toarray(), columns=vect.get_feature_names())\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    1     3   2       1        1    1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document Frequency\n",
    "vect = CountVectorizer(binary=True)\n",
    "df = vect.fit_transform(simple_train).toarray().sum(axis=0)\n",
    "pd.DataFrame(df.reshape(1, 6), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab      call   me  please  tonight  you\n",
       "0  0.0  0.333333  0.0     0.0      1.0  1.0\n",
       "1  1.0  0.333333  0.5     0.0      0.0  0.0\n",
       "2  0.0  0.333333  0.5     2.0      0.0  0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Term Frequency-Inverse Document Frequency (simple version)\n",
    "tf/df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.652491</td>\n",
       "      <td>0.652491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.720333</td>\n",
       "      <td>0.425441</td>\n",
       "      <td>0.547832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266075</td>\n",
       "      <td>0.342620</td>\n",
       "      <td>0.901008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cab      call        me    please   tonight       you\n",
       "0  0.000000  0.385372  0.000000  0.000000  0.652491  0.652491\n",
       "1  0.720333  0.425441  0.547832  0.000000  0.000000  0.000000\n",
       "2  0.000000  0.266075  0.342620  0.901008  0.000000  0.000000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TfidfVectorizer\n",
    "vect = TfidfVectorizer()\n",
    "pd.DataFrame(vect.fit_transform(simple_train).toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Using TF-IDF to Summarize a Yelp Review\n",
    "\n",
    "> **Note:** Reddit's autotldr uses the [SMMRY](http://smmry.com/about) algorithm, which is based on TF-IDF!\n",
    "\n",
    "### 8.1 Build a TF-IDF predictor matrix excluding stopwords with `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28880)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a document-term matrix using TF-IDF\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "dtm = vect.fit_transform(yelp.text)\n",
    "features = vect.get_feature_names()\n",
    "dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Write a function to pull out the top 5 words by TF-IDF score from a review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize():\n",
    "    \n",
    "    # choose a random review that is at least 300 characters\n",
    "    review_length = 0\n",
    "    while review_length < 300:\n",
    "        review_id = np.random.randint(0, len(yelp))\n",
    "        review_text = str(yelp.text[review_id], 'utf-8')\n",
    "        review_length = len(review_text)\n",
    "    \n",
    "    # create a dictionary of words and their TF-IDF scores\n",
    "    word_scores = {}\n",
    "    for word in TextBlob(review_text).words:\n",
    "        word = word.lower()\n",
    "        if word in features:\n",
    "            word_scores[word] = dtm[review_id, features.index(word)]\n",
    "    \n",
    "    # print words with the top 5 TF-IDF scores\n",
    "    print('TOP SCORING WORDS:')\n",
    "    top_scores = sorted(list(word_scores.items()), key=lambda x: x[1], reverse=True)[:5]\n",
    "    for word, score in top_scores:\n",
    "        print(word)\n",
    "    \n",
    "    # print 5 random words\n",
    "    print('\\n' + 'RANDOM WORDS:')\n",
    "    random_words = np.random.choice(list(word_scores.keys()), size=5, replace=False)\n",
    "    for word in random_words:\n",
    "        print(word)\n",
    "    \n",
    "    # print the review\n",
    "    print('\\n' + review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP SCORING WORDS:\n",
      "philly\n",
      "casella\n",
      "33rd\n",
      "family\n",
      "celebrating\n",
      "\n",
      "RANDOM WORDS:\n",
      "fool\n",
      "lbs\n",
      "immediately\n",
      "deli\n",
      "oven\n",
      "\n",
      "I was inspired to visit Casella's after a coworker told me about their authentically Italian goodness. As my tummy growled today, I was in the neighborhood so I knew just where to go. I walked into a simple yet clean deli. Immediately, I was welcomed by the entire staff (I believe they are all related or at least family through friendship). They asked me if it was my first time in and I said yes, so right away they started giving me a history of the shop and the tasty cuisine. Celebrating their 33rd anniversary (congrats!!), I learned that everything is homemade -- from the meatballs to the chicken salad. The owner said he goes through 40 lbs of chicken a week. He gave me a sample and the chicken was chunky and delicious. I'm not surprised he has to prepare so much chicken every week! The meatballs and freshly cut meat for Philly Cheese-steak sandwiches looked great too! The owner mentioned he is from Philly so better be ready for some authentic Philly and Italian style cookin'! \n",
      "\n",
      "While I was there, the owner was slicing some fresh provolone, so I added that to the warmed turkey sandwich I ordered. The turkey was tasty, the provolone was yummy and the sourdough roll tasted like it was fresh from the oven. It was $8 for a sandwich and soda but the sandwich was hefty enough that I saved half for later. As I walked out, everyone said goodbye to me and I felt like I was leaving a family dinner. \n",
      "\n",
      "In summary, here's what made Casella's stand out: \n",
      "\n",
      "- The very friendly staff\n",
      "- It's a local family-owned neighborhood deli celebrating their 33rd anniversary. Gotta support the local businesses! \n",
      "- Clean decor \n",
      "- Tasty, homemade food that's on display for visitors to see \n",
      "- A good family-style atmosphere that greets you the second you walk inside. \n",
      "\n",
      "I'm not sure how it's taken my so long to find this local treat, but now that I've found it, I plan on becoming a regular. \n",
      "\n",
      "Directions: Note that this is hidden in the Basha's strip mall (on the side of Granite Reef) but don't let that fool you!\n"
     ]
    }
   ],
   "source": [
    "summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Extract sentiment from a review parsed with `TextBlob`\n",
    "\n",
    "Sentiment polarity ranges from -1, the most negative, to 1, the most positive. A parsed TextBlob object has sentiment which can be accessed with:\n",
    "\n",
    "    review.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.\n",
      "\n",
      "Do yourself a favor and get their Bloody Mary.  It was phenomenal and simply the best I've ever had.  I'm pretty sure they only use ingredients from their garden and blend them fresh when you order it.  It was amazing.\n",
      "\n",
      "While EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  It was the best \"toast\" I've ever had.\n",
      "\n",
      "Anyway, I can't wait to go back!\n"
     ]
    }
   ],
   "source": [
    "print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40246913580246907"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# polarity ranges from -1 (most negative) to 1 (most positive)\n",
    "review.sentiment.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Calculate the sentiment for every review in the full Yelp dataset as a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that accepts text and returns the polarity\n",
    "def detect_sentiment(text):\n",
    "    return TextBlob(text.decode('utf-8')).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new DataFrame column for sentiment (WARNING: SLOW!)\n",
    "yelp['sentiment'] = yelp.text.apply(detect_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'business_id', u'date', u'review_id', u'stars', u'text', u'type',\n",
       "       u'user_id', u'cool', u'useful', u'funny', u'sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yelp_best_worst = yelp[(yelp.stars==5) | (yelp.stars==1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Create a boxplot of sentiment by star rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11a4254d0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEcCAYAAAAGD4lRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nImZJxBhjTMQsiRhjjInY/wcOHOoiADGgggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a425dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# box plot of sentiment grouped by stars\n",
    "yelp.boxplot(column='sentiment', by='stars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 Print reviews with the highest and lowest sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254    Our server Gary was awesome. Food was amazing....\n",
       "347    3 syllables for this place. \\nA-MAZ-ING!\\n\\nTh...\n",
       "420                                    LOVE the food!!!!\n",
       "459    Love it!!! Wish we still lived in Arizona as C...\n",
       "679                                     Excellent burger\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reviews with most positive sentiment\n",
    "yelp[yelp.sentiment == 1].text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "773     This was absolutely horrible. I got the suprem...\n",
       "1517                  Nasty workers and over priced trash\n",
       "3266    Absolutely awful... these guys have NO idea wh...\n",
       "4766                                       Very bad food!\n",
       "5812        I wouldn't send my worst enemy to this place.\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reviews with most negative sentiment\n",
    "yelp[yelp.sentiment == -1].text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. [Bonus] Explore fun TextBlob features\n",
    "\n",
    "### 10.1 Correct spelling with `.correct()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"15 minutes late\")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spelling correction\n",
    "TextBlob('15 minuets late').correct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Perform spellchecking with `.spellcheck()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('part', 0.9929478138222849), (u'parrot', 0.007052186177715092)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spellcheck\n",
    "Word('parot').spellcheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Extract definitions with `.define()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'sloping land (especially the slope beside a body of water)',\n",
       " u'a financial institution that accepts deposits and channels the money into lending activities',\n",
       " u'a long ridge or pile',\n",
       " u'an arrangement of similar objects in a row or in tiers',\n",
       " u'a supply or stock held in reserve for future use (especially in emergencies)',\n",
       " u'the funds held by a gambling house or the dealer in some gambling games',\n",
       " u'a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force',\n",
       " u'a container (usually with a slot in the top) for keeping money at home',\n",
       " u'a building in which the business of banking transacted',\n",
       " u'a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# definitions\n",
    "Word('bank').define('n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- NLP is a gigantic field\n",
    "- Understanding the basics broadens the types of data you can work with\n",
    "- Simple techniques go a long way\n",
    "- Use scikit-learn for NLP whenever possible"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
